---
title: "Programs"
author:
  '1':
    name: Lars Vilhuber
  '2':
    name: Flavio Stanchi
  '3':
    name: Hautahi Kingi
  '4':
    name: Sylverie Herbert
date: "`r Sys.Date()`"
output:
  html_document: 
    keep_md: yes
    number_sections: yes
    toc: yes
  word_document: default
  pdf_document: default
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(eval=FALSE)
```
# Programs

## Setup


```{r setup_config,eval=TRUE}
source(file.path(rprojroot::find_rstudio_root_file(),"pathconfig.R"),echo=TRUE)
```

Note that the path `interwrk` is transitory, and is only kept during processing. It will be empty in the replication archive.

Any libraries needed are called and if necessary installed through `libraries.R`:

```{r setup_libraries,eval=TRUE}
source(file.path(basepath,"global-libraries.R"),echo=TRUE)
source(file.path(programs,"libraries.R"), echo=TRUE)
```

Most parameters are set in the `config.R`:

```{r setup_config2,eval=TRUE}
source(file.path(programs,"config.R"), echo=TRUE)
```


## Data cleaning and merging

We combine our collected data with bibliometric data, both manually extracted from "Web of Science" and collected from CrossRef. We also download the cleaned data for both the replication and the Web of Science data here. These programs should be runnable by anybody.



## Download the replication data from Zenodo
The responses to the replication attempts are stored on Google Sheets, and considered private. We have separately cleaned the data,  anonymized it, and uploaded to Zenodo (see https://www.github.com/labordynamicsinstitute/ldi-replication-dataprep). Here, we simply download the data, with a bit of additional data cleaning. 

 - Input data: On Zenodo
 - Output data: path `interwrk',"repllist2.Rds"
 
```{r download_replication}
source(file.path(programs,"01_download_replication_data.R"),echo=TRUE)
```

At the end of this step, the `interwrk` directory  should have the following data files:

- entryQ_pub.Rds - the main data from the "Entry" questionnaire (assessment) 
- exitQ_pub.Rds - the main data from the post-replication "Exit" questionnaire (assessment)
- replication_list_pub.Rds -  the assignment spreadsheet. 


## Get CrossRef information
The master replication list has all the DOIs. We   look up the DOI at CrossRef.


Note: downloading references from CrossRef can take a while. The code contains a fallback - if the file `crossref_info.Rds`  exists, no new pull will be computed. To override, delete the file. 

 - inputs: entryQ_pub, exitQ_pub, replication list (in `dataloc`)
 - outputs: crossref_info.Rds (in `crossrefloc`) and intermediate raw data in `interwrk`

```{r get_crossref,eval=TRUE}
source(file.path(programs,"02_get_crossref.R"),echo=TRUE)
```

### Some diagnostics

When finding DOIs, some articles might not be found. When that is the case, they are reported here.

```{r doi_diagnostics,echo=TRUE,eval=TRUE,cache=TRUE}
if ( file.exists(file.path(interwrk,"crossref.diagnostics.Rds"))) {
  crossref.diagnostics <- readRDS(file=file.path(interwrk,"crossref.diagnostics.Rds"))
} else {
  crossref.diagnostics <- data.frame()
}
```

###- DOIs to download (unique DOIs in all replication files): **r NROW(dois.df) **
###- DOIs successfully looked up on CrossRef: **r nrow(bibinfo.df)**
###- DOIs not found: **r nrow(crossref.diagnostics)**   (should be ZERO)

```{r doi_diagnostics2,echo=FALSE,eval=TRUE}
if ( nrow(crossref.diagnostics) > 0 ) {
  knitr::kable(crossref.diagnostics)
}

```


```{r clean_replication,cache=TRUE}
source(file.path(programs,"04_clean_replicationlist.R"),echo=TRUE)
```



## Download the h-index information

```{r download_hindex,eval=TRUE,cache=TRUE}
source(file.path(programs,"06_gen_hindex_list.R"),echo=TRUE)
```
```{r clean_hindex,eval=TRUE,cache=TRUE}
source(file.path(programs,"07_readclean_hindex_list.R"),echo=TRUE)
```

## Collect Bibtex info on the articles

```{r}
# This program collects bibtex information for all the DOIs read by the replicators from crossref
# It will skip processing if the previously collected data is there.
# Relies on CrossRef API, which can be fragile.
source(file.path(programs,"08_get_crossref_bibs.R"),echo=TRUE)
```


## Paper analysis

The paper analysis is run in the `3x*.R`  programs.

```{r prepare_paper,eval=TRUE}
source(file.path(programs,'25_prepare_sample.R'),echo=TRUE)
source(file.path(programs,'30_results1.R'),echo=TRUE)
source(file.path(programs,'31_results2.R'),echo=TRUE)
#source(file.path(programs,'20_analytics.R'),echo=TRUE) 
source(file.path(programs,'32_conclusion.R'),echo=TRUE)
#source(file.path(programs,'33_tables.R'),echo=TRUE)   # incorporated into 20_analytics.R
#source(file.path(programs,'34_figures.R'),echo=TRUE)  # incorporated into 20_analytics.R
#source(file.path(programs,'35_appendix.R'),echo=TRUE)
source(file.path(programs,'36_list-articles.R'),echo=TRUE)
```

Note that the path `interwrk` is transitory, and is only kept during processing. It will be empty in the replication archive.

## Outputs

Some numbers are written out to `TexIncludes` (here: `r TexIncludes`) as LaTeX files with a single number. Tables and figures are written out to `Outputs` (here: `r Outputs`). 

Key datasets:

- Complete sample: `r file.path(dataloc,"00_complete_sample.Rds")`, keyed by DOI.

## Revision 1

After referee reports, the following supplementary analysis has been added:

### Adding a clean count of the number of articles in the universe

```{r clean_count_dois,eval=TRUE}
source(file.path(programs,'40_supplementary1.R'),echo=TRUE)
```


### Update citations with the latest

Referees wanted to see an updated citation analysis. While we keep the original analysis as-is, the following extracts newer per-year citation counts from openAlex. 



```{r update_citations,eval=TRUE,cache=FALSE}
source(file.path(programs,'41_supplementary2.R'),echo=TRUE)
```


The first output file is `r openalex.Rds`, an extract of OpenAlex for all articles in the sample, with


```{r,eval=TRUE}
names(readRDS(openalex.Rds))
```

Key to match back to the internal database is `DOI`, a transformation of the OpenAlex-provided `doi` (renamed to `doi.url`. Note that the field `author` contains a list of author ids, as follows:

```{r,eval=TRUE}
readRDS(openalex.Rds) %>% select(author) %>% tidyr::unnest(author) %>% names()
```

The column `au_id` is key to matching in later OpenAlex information computed. 

The final output file (`r citations.latest`) is keyed on `DOI` per article, and has both within-year citations, and cumulative year-to-date citations. These must be recomputed based on the available data, because the OpenAlex API only has 10 years worth of data, but the max citations is (?) accurate.


```{r,eval=TRUE}

names(readRDS(citations.latest))

```

### Get information on all authors, so we can compute h-index

This is used in several of the following programs. It can take up to 1 hour to run.


```{r update_author_openalex,eval=TRUE}
source(file.path(programs,'42_prepare_authors.R'),echo=TRUE)
```


Output files:

- openalex.authors.Rds - all works for in-scope authors (authors having published during the time period in AEJ:AE)

Intermediate files

- file.path(interwrk,"authors.df.Rds")) - these are all the *works* by the authors in the sample

Input files:

- file.path(openalexloc,"blacklist.xlsx") - an edited list of author ids to remove, since impossible to find proper data on OpenAlex (usually, because of very very bad name disambiguation)


### Institutional affiliations, mapped to regions, also productivity of those institutions 

There are some authors for whom we did not have institutions; we hand-edited some of those. These can be found in

- `r file.path(crossrefloc,"affiliation-impute.xlsx")`

```{r update_institutions,eval=TRUE}
source(file.path(programs,'43_supplementary4.R'),echo=TRUE)
```



### Getting at experience

In order to get publication experience, we use the first observed publications for an author. This hinges on entity disambiguation by OpenAlex, which does not always get it right. We audited some extreme values, and manually searched for authors' first publication or obtention of Ph.D. 


```{r update_experience,eval=TRUE}
source(file.path(programs,'44_supplementary_authexp.R'),echo=TRUE)
```

- Output: `r file.path(interwrk,"authors.exp.df.Rds")`
- Audit file: `r file.path(crossrefloc,"audit-exp.xlsx"))`


### Recomputing h-index

In order to recompute the h-index, we pull ALL works by each of the authors in our set, compute year-to-date citations, and compute a as-of-year h-index.

- At least one author was mis-matched by OpenAlex, and the mismatched entity is on a blacklist.

```{r update_hindex,eval=TRUE}
source(file.path(programs,'45_supplementary_hindex.R'),echo=TRUE)
```

Output files:

- openalex.hindex - per-author-year hindex

Intermediate files:

- file.path(interwrk,"citations.df.Rds")) - these are the citations of those works. It can be expanded from the authors.df.

Auxiliary files:

- At least one author was mis-matched by OpenAlex, and the mismatched entity is on a blacklist. `r file.path(crossrefloc,"blacklist.xlsx")`

The final output file `openalex.hindex` (`r openalex.hindex`) is keyed on the OpenAlex author id `au_id`

```{r,eval=TRUE}
names(hindex.by.year)
```

Here's an example:
```{r,results='asis',eval=TRUE}
# test whether this seems reasonable

#citations.df %>% filter(au_id=="https://openalex.org/A5027614993") %>% kable()
hindex.by.year %>% filter(au_id=="https://openalex.org/A5027614993") %>% kable()

authors.df %>% filter(article_id=="https://openalex.org/W2577227262") %>% kable()
citations.df %>% filter(article_id=="https://openalex.org/W2577227262") %>% kable()
```
